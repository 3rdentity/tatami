index:
  number_of_shards: 1

  analysis:
    analyzer:
      default:
        type: "custom"
        tokenizer: "standard"
        filter: ["lowercase", "stop_francais", "fr_stemmer", "asciifolding", "elision"]
    filter:
      stop_francais:
        type: "stop"
        stopwords: ["_french_"]
      fr_stemmer:
        type: "stemmer"
        name: "french"
      elision:
        type: "elision"
        articles: ["l", "m", "t", "qu", "n", "s", "j", "d"]
